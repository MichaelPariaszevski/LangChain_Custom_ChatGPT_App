{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Custom ChatGPT App with LangChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv, find_dotenv \n",
    "\n",
    "load_dotenv(find_dotenv(), override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: Your are a chatbot having a conversation with a human.\n",
      "Human: What is the distance to the moon\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "{'content': 'What is the distance to the moon', 'text': 'The distance to the moon is approximately 384,400 kilometers (238,855 miles) on average.'}\n",
      "--------------------------------------------------\n",
      "Goodbye\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI \n",
    "from langchain.schema import SystemMessage \n",
    "from langchain.chains import LLMChain \n",
    "from langchain.prompts import ChatPromptTemplate, HumanMessagePromptTemplate \n",
    "\n",
    "llm=ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=1) \n",
    "\n",
    "prompt=ChatPromptTemplate(\n",
    "    input_variables=[\"content\"],\n",
    "    messages=[\n",
    "        SystemMessage(content=\"Your are a chatbot having a conversation with a human.\"), \n",
    "        HumanMessagePromptTemplate.from_template(\"{content}\")\n",
    "    ]\n",
    ") \n",
    "\n",
    "# verbose=True is good for debugging, otherwise use verbose=False\n",
    "\n",
    "chain=LLMChain(llm=llm, prompt=prompt, verbose=True) \n",
    "\n",
    "while True: \n",
    "    content=input(\"Your prompt: \") \n",
    "    if content in [\"quit\", \"exit\", \"bye\"]: \n",
    "        print(\"Goodbye\") \n",
    "        break\n",
    "    response=chain.invoke({\"content\": content}) \n",
    "    print(response)\n",
    "    print(\"-\"*50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Incorporating Memory in LangChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: Your are a chatbot having a conversation with a human.\n",
      "Human: Earth's mass is ...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "{'content': \"Earth's mass is ...\", 'chat_history': [HumanMessage(content=\"Earth's mass is ...\"), AIMessage(content=\"The mass of the Earth is approximately 5.97 x 10^24 kilograms. Is there anything else you'd like to know about Earth's mass?\")], 'text': \"The mass of the Earth is approximately 5.97 x 10^24 kilograms. Is there anything else you'd like to know about Earth's mass?\"}\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: Your are a chatbot having a conversation with a human.\n",
      "Human: Earth's mass is ...\n",
      "AI: The mass of the Earth is approximately 5.97 x 10^24 kilograms. Is there anything else you'd like to know about Earth's mass?\n",
      "Human: and its diameter is ...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "{'content': 'and its diameter is ...', 'chat_history': [HumanMessage(content=\"Earth's mass is ...\"), AIMessage(content=\"The mass of the Earth is approximately 5.97 x 10^24 kilograms. Is there anything else you'd like to know about Earth's mass?\"), HumanMessage(content='and its diameter is ...'), AIMessage(content=\"The average diameter of the Earth is about 12,742 kilometers (7,918 miles). This measurement is taken from the surface through the center and back up to the other side. Do you have any other questions about Earth's dimensions or characteristics?\")], 'text': \"The average diameter of the Earth is about 12,742 kilometers (7,918 miles). This measurement is taken from the surface through the center and back up to the other side. Do you have any other questions about Earth's dimensions or characteristics?\"}\n",
      "--------------------------------------------------\n",
      "Goodbye\n"
     ]
    }
   ],
   "source": [
    "# New imports \n",
    "\n",
    "from langchain.memory import ConversationBufferMemory \n",
    "from langchain.prompts import MessagesPlaceholder \n",
    "\n",
    "llm_2=ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=1) \n",
    "\n",
    "# Added memory=ConversationBufferMemory()\n",
    "\n",
    "memory=ConversationBufferMemory(\n",
    "    memory_key=\"chat_history\", \n",
    "    return_messages=True\n",
    ")\n",
    "\n",
    "# Added: MessagesPlaceholder(variable_name=\"chat_history\")\n",
    "\n",
    "prompt=ChatPromptTemplate(\n",
    "    input_variables=[\"content\"],\n",
    "    messages=[\n",
    "        SystemMessage(content=\"Your are a chatbot having a conversation with a human.\"), \n",
    "        MessagesPlaceholder(variable_name=\"chat_history\"), # This is where the memory will be stored \n",
    "        HumanMessagePromptTemplate.from_template(\"{content}\")\n",
    "    ]\n",
    ") \n",
    "\n",
    "# verbose=True is good for debugging, otherwise use verbose=False\n",
    "\n",
    "# Added chain=LLMChain(memory=memory)\n",
    "\n",
    "chain=LLMChain(\n",
    "    llm=llm_2, \n",
    "    prompt=prompt, \n",
    "    memory=memory, \n",
    "    verbose=True\n",
    "    )\n",
    "\n",
    "\n",
    "while True: \n",
    "    content=input(\"Your prompt: \") \n",
    "    if content in [\"quit\", \"exit\", \"bye\"]: \n",
    "        print(\"Goodbye\") \n",
    "        break\n",
    "    response=chain.invoke({\"content\": content}) \n",
    "    print(response)\n",
    "    print(\"-\"*50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LangChain_1_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
